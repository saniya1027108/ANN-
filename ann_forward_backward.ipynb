{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkpyNuONK0-J",
        "outputId": "168d1bcb-6b5b-42d1-abb9-94e3db0a754f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 0.37576822440088853\n",
            "Epoch 100: Loss = 0.25000908090944446\n",
            "Epoch 200: Loss = 0.24874928368492294\n",
            "Epoch 300: Loss = 0.24776205528943876\n",
            "Epoch 400: Loss = 0.24682863089669319\n",
            "Epoch 500: Loss = 0.24582675007406454\n",
            "Epoch 600: Loss = 0.2446720402416236\n",
            "Epoch 700: Loss = 0.24329336661544615\n",
            "Epoch 800: Loss = 0.2416200461295801\n",
            "Epoch 900: Loss = 0.23957575937100914\n",
            "Predictions: [[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        self.weights1 = np.random.randn(self.num_inputs, self.num_hidden)\n",
        "        self.weights2 = np.random.randn(self.num_hidden, self.num_outputs)\n",
        "\n",
        "        self.bias1 = np.zeros((1, self.num_hidden))\n",
        "        self.bias2 = np.zeros((1, self.num_outputs))\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        self.hidden_layer = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_activation = self.sigmoid(self.hidden_layer)\n",
        "\n",
        "        self.output_layer = np.dot(self.hidden_activation, self.weights2) + self.bias2\n",
        "        self.output_activation = self.sigmoid(self.output_layer)\n",
        "\n",
        "        return self.output_activation\n",
        "\n",
        "    def backward_propagation(self, X, y, learning_rate):\n",
        "        error = self.output_activation - y\n",
        "\n",
        "        derivative_output = self.sigmoid_derivative(self.output_layer)\n",
        "        delta_output = error * derivative_output\n",
        "\n",
        "        error_hidden = np.dot(delta_output, self.weights2.T)\n",
        "        derivative_hidden = self.sigmoid_derivative(self.hidden_layer)\n",
        "        delta_hidden = error_hidden * derivative_hidden\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_activation.T, delta_output)\n",
        "        self.bias2 -= learning_rate * np.sum(delta_output, axis=0, keepdims=True)\n",
        "\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, delta_hidden)\n",
        "        self.bias1 -= learning_rate * np.sum(delta_hidden, axis=0, keepdims=True)\n",
        "\n",
        "    def train(self, X, y, learning_rate, num_epochs):\n",
        "        for epoch in range(num_epochs):\n",
        "            output = self.forward_propagation(X)\n",
        "            self.backward_propagation(X, y, learning_rate)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                loss = self.mean_squared_error(output, y)\n",
        "                print(f\"Epoch {epoch}: Loss = {loss}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward_propagation(X)\n",
        "        predictions = np.round(output)\n",
        "        return predictions\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    def mean_squared_error(self, y_pred, y_true):\n",
        "        return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input data\n",
        "y = np.array([[0], [1], [1], [0]])  # Target output\n",
        "\n",
        "# Initialize and train the neural network\n",
        "nn = NeuralNetwork(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "nn.train(X, y, learning_rate=0.1, num_epochs=1000)\n",
        "\n",
        "# Make predictions on new data\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "predictions = nn.predict(test_data)\n",
        "print(\"Predictions:\", predictions)\n"
      ]
    }
  ]
}